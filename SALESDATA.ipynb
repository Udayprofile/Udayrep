{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcFE20m0B8x+dSWzbLKK8f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Udayprofile/Udayrep/blob/main/SALESDATA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am here Creating a Sales Data Analysis Project. Where, I am Going to generate sample sales data, clean it, and Analyse trends using PySpark and SQL\n"
      ],
      "metadata": {
        "id": "W_pApfKy1qAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing and installing the essential libraries required.\n"
      ],
      "metadata": {
        "id": "A1Y1471G2W6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "import pandas as pd\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, sum, avg, count, to_date\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ELyjnpy2hMS",
        "outputId": "40b9eae1-9292-4b6d-e527-602b1186c2aa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.4)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Spark session\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rgWus55X2pom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"SalesDataAnalysis\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "7dfFmoAh0m_G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating Synthetic Sales Data\n",
        "\n",
        "I am creating here 1000 random sales records with columns:\n",
        "\n",
        "Order_ID: Unique order number\n",
        "\n",
        "Date: Random date in the last 6\n",
        "\n",
        "Product: Random product name\n",
        "\n",
        "Category: Product category\n",
        "\n",
        "Quantity: Random quantity (1-10)\n",
        "\n",
        "Price: Random price (₹100-₹1000)\n",
        "\n",
        "Total_Sale: Quantity × Price\n"
      ],
      "metadata": {
        "id": "ohomx19i2yxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random sales data\n",
        "products = [\"Laptop\", \"Mobile\", \"Tablet\", \"Smartwatch\", \"Headphones\", \"Camera\"]\n",
        "categories = {\"Laptop\": \"Electronics\", \"Mobile\": \"Electronics\", \"Tablet\": \"Electronics\",\n",
        "              \"Smartwatch\": \"Wearable\", \"Headphones\": \"Accessories\", \"Camera\": \"Photography\"}\n",
        "\n",
        "sales_data = []\n",
        "start_date = datetime.today() - timedelta(days=180)  # Last 6 months\n",
        "\n",
        "for i in range(1000):\n",
        "    date = start_date + timedelta(days=random.randint(0, 180))\n",
        "    product = random.choice(products)\n",
        "    category = categories[product]\n",
        "    quantity = random.randint(1, 10)\n",
        "    price = random.randint(100, 1000)\n",
        "    total_sale = quantity * price\n",
        "    sales_data.append([i+1, date.strftime('%Y-%m-%d'), product, category, quantity, price, total_sale])\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "columns = [\"Order_ID\", \"Date\", \"Product\", \"Category\", \"Quantity\", \"Price\", \"Total_Sale\"]\n",
        "sales_df = pd.DataFrame(sales_data, columns=columns)\n",
        "\n",
        "# Convert Pandas DF to Spark DF\n",
        "spark_df = spark.createDataFrame(sales_df)\n",
        "\n",
        "# Show first few rows\n",
        "spark_df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqlJW9v50sqD",
        "outputId": "aa221829-a5ad-4877-ae3d-bdc08e2e3533"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+----------+-----------+--------+-----+----------+\n",
            "|Order_ID|      Date|   Product|   Category|Quantity|Price|Total_Sale|\n",
            "+--------+----------+----------+-----------+--------+-----+----------+\n",
            "|       1|2024-10-17|Headphones|Accessories|       2|  577|      1154|\n",
            "|       2|2024-12-31|    Tablet|Electronics|      10|  573|      5730|\n",
            "|       3|2025-02-11|    Mobile|Electronics|       9|  279|      2511|\n",
            "|       4|2024-11-02|    Laptop|Electronics|       5|  480|      2400|\n",
            "|       5|2024-12-02|Smartwatch|   Wearable|       9|  632|      5688|\n",
            "+--------+----------+----------+-----------+--------+-----+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning\n",
        "Converting the Date column to proper date format\n",
        "Remove duplicate records (if any)"
      ],
      "metadata": {
        "id": "CrY9mb8-29wU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df = spark_df.withColumn(\"Date\", to_date(col(\"Date\")))\n",
        "spark_df = spark_df.dropDuplicates()\n",
        "spark_df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTf-sJ8G0x1X",
        "outputId": "aed4ba95-8366-4d47-cb33-a81946723841"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Order_ID: long (nullable = true)\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Category: string (nullable = true)\n",
            " |-- Quantity: long (nullable = true)\n",
            " |-- Price: long (nullable = true)\n",
            " |-- Total_Sale: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing SQL Queries in PySpark\n",
        "Registeing DataFrame as SQL Table:"
      ],
      "metadata": {
        "id": "aAxMUZCY3mDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.createOrReplaceTempView(\"sales_data\")\n"
      ],
      "metadata": {
        "id": "FFuATLkP04aX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Sales by Product"
      ],
      "metadata": {
        "id": "t77M_ZKD3xsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT Product, SUM(Total_Sale) as TotalRevenue FROM sales_data GROUP BY Product ORDER BY TotalRevenue DESC\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUIOcvdX06bo",
        "outputId": "f420ca49-78f6-49cc-f4e1-c0be2fc70993"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+\n",
            "|   Product|TotalRevenue|\n",
            "+----------+------------+\n",
            "|    Camera|      568832|\n",
            "|    Mobile|      558369|\n",
            "|    Laptop|      525258|\n",
            "|Smartwatch|      468205|\n",
            "|Headphones|      453828|\n",
            "|    Tablet|      395601|\n",
            "+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average sales per Category"
      ],
      "metadata": {
        "id": "kdN_TWjD31qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT Category, AVG(Total_Sale) as AvgSale FROM sales_data GROUP BY Category\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk6MpQIU1BN_",
        "outputId": "7fd3c944-db02-4a18-c213-77d5dc19e3de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|   Category|           AvgSale|\n",
            "+-----------+------------------+\n",
            "|   Wearable|3060.1633986928105|\n",
            "|Electronics| 3006.560975609756|\n",
            "|Accessories|2801.4074074074074|\n",
            "|Photography| 2947.316062176166|\n",
            "+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most Sold products"
      ],
      "metadata": {
        "id": "4Ji_aym938XJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT Product, SUM(Quantity) as TotalUnitsSold FROM sales_data GROUP BY Product ORDER BY TotalUnitsSold DESC LIMIT 5\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C64ZYj1k1Fo-",
        "outputId": "27502709-a99a-480f-f60c-c0d464839634"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------+\n",
            "|   Product|TotalUnitsSold|\n",
            "+----------+--------------+\n",
            "|    Camera|          1055|\n",
            "|    Mobile|           969|\n",
            "|    Laptop|           939|\n",
            "|Headphones|           854|\n",
            "|Smartwatch|           844|\n",
            "+----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAVING the results"
      ],
      "metadata": {
        "id": "vDl458u64Cn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.write.csv(\"sales_data_cleaned.csv\", header=True)\n"
      ],
      "metadata": {
        "id": "QvFdRwKU1JLg"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}